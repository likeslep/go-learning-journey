# 并行编程

## 进程和线程
操作系统会为应用程序创建一个进程，作为一个应用程序，它像一个为所有资源而运行的容器。这些资源包括内存地址空间、文件句柄、设备和线程。
线程是操作系统调度的一种执行路径，用于在处理器执行我们在函数中编写的代码。一个进程从一个线程开始，即主线程，当该线程终止时，进程终止。这是因为主线程是应用程序的原点。然后主线程可以一次启动更多的线程，而这些线程可以启动更多的线程。

## Keep yourself busy or do the work yourself

空的 select 语句将永远阻塞

```go
func main() {
    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintln(w, "Hello, GopherCon SG")
    })
    go func() {
        if err := http.ListenAndServe(":8080", nil); err != nil {
            log.Fatal(err)
        }
    }()

    select {} 
}
```

**如果你的 goroutine 在从另一个 goroutine 获得结果之前无法取得进展，那么通常情况下，你自己去做这项工作比委托它（go func()）更简单。**

这通常消除了将结果从 goroutine 返回到启动器所需的大量状态跟踪和 `chan` 操作。
```go
func main() {
    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintln(w, "Hello, GopherCon SG")
    })

    if err := http.ListenAndServe(":8080", nil); err != nil {
        log.Fatal(err)
    }
}
```

不要为了并发而并发，在决定是否启动 goroutine 时，需要仔细权衡成本与收益。我们要清楚：启动 goroutine 有成本、同步开销可能超过收益。

## Leave concurrency to the caller 将并发交给调用方来决定

这两个API有什么区别？
```go
func ListDirectory1(dir string)([]string, error)

func ListDirectory2(dir string) chan string 
```
- `ListDirectory1` 将目录读取到一个 slice 中，然后返回整个切片，或者如果出现错误，则返回错误。这是同步调用的，`ListDirectory1` 的调用方会阻塞，直到读取所有目录条目.根据目录的大小，这可能需要很长时间，并且可能会分配大量内存来构建目录条目名称的slice。
- `ListDirectory2` 返回一个 `chan string`，将通过该 chan 传递目录。当通道关闭时，这表示不再有目录。由于在 `ListDirectory2` 返回后发生通道的填充，`ListDirectory2` 可能内部启动 goroutine 来填充通道。
**Goroutine的声明周期独立于创建它的函数，一旦启动，就有自己的执行流。函数返回不影响goroutine，只有main函数结束才会终止所有goroutine。**

`ListDirectory2` 版本还有两个问题：
1. 它通过一个关闭的通道作为不再需要处理的项目的信号，但是调用者不知道通过通道返回的项目集完不完整，因为中途也可能出现了错误。调用者无法区分空目录与完全从目录读取的错误之间的区别。这两种情况都会导致从`ListDirectory2`返回的通道会立即关闭。
2. 调用者必须持续从通道中读取数据，直到它关闭。因为这是调用者知道填充chan的goroutine已经停止的唯一方法。这对ListDirectory的使用是一个严重的限制，调用者必须花时间从通道读取数据，即使它可能已经得到它想要的答案。对于大中型目录，他可能在内存使用方面更为高效，但这种方法并不比原始的基于slice的方法快。

```go
func ListDirectory(dir string, fn func(string))
```
filepath.WalkDir也是类似的模型，如果函数启动goroutine
，则必须向调用方提供显式停止该goroutine的方法。通常，将异步执行函数的决定权交给该函数的调用方通常更容易。

## Never start a goroutine without knowing when it will stop

```go
func leak() {
    ch := make(chan int)

    go func() {
        val := <-ch
        fmt.Println("We received a value:", val)
    }
}
```
在这个例子中，函数内部启动了一个goroutine，决定权在函数里边。因为没有任何东西发送给这个channel，但协程中要从这个channel中取值，所以这个协程会一直阻塞在这里，导致它永远不会退出，这个时候就产生了goroutine泄露。

任何时候启动一个goroutine必须问自己：
- 它什么时候会结束
- 你有没有一个办法来结束它

```go
func main() {
    mux := http.NewServeMux()
    mux.HandleFunc("/", func(resp http.ResponseWriter, req *http.Request) {
        fmt.Fprintln(resp, "Hello, QCon!")
    })
    go http.ListenAndServe("127.0.0.1:8001", http.DefaultServeMux)
    http.ListenAndServe("0.0.0.0:8080", mux)
}
```
这个应用程序在两个不同的端口上提供http流量，端口8080用于应用程序流量，8001用于访问/debug/pprof端点。

```go
func serveApp() {
    mux := http.NewServeMux()
    mux.HandleFunc("/", func(resp http.ResponseWriter, req *http.Request) {
        fmt.Fprintln(resp, "Hello, QCon!")
    })
    http.ListenAndServe("0.0.0.0:8080", mux)
}

func serveDebug() {
    http.ListenAndServe("0.0.0.0:8081", mux)
}

func main() {
    go serveDebug()
    serveApp()
}
```
优化后的代码如上，通过将serveApp和serveDebug处理程序分解为各自的函数，我们还遵循上边的建议，确保serveApp和serveDebug将他们的并发性留给调用者。但代码还是会存在一些问题，如果`serveApp()`返回，则 main.main 将返回导致程序关闭，只能靠类似 supervisor进程管理来重置启动。然而，`serveDebug()`是在一个单独的 goroutine 中运行的，如果它返回，那么所在的 goroutine 将退出，而程序的其余部分继续运行。因此对以上的代码进一步改进：

```go
func serveApp() {
    mux := http.NewServeMux()
    mux.HandleFunc("/", func(resp http.ResponseWriter, req *http.Request) {
        fmt.Fprintln(resp, "Hello, QCon!")
    })
    if err := http.ListenAndServe("0.0.0.0:8080", mux); err != nil {
        log.Fatal(err)
    }
}

func serveDebug() {
    if err := http.ListenAndServe("0.0.0.0:8081", mux); err != nil {
        log.Fatal(err)
    }
}

func main() {
    go serveDebug()
    go serveApp()
    select{}
}
```
以上代码解决了一个协程的退出不会影响到另一个协程，但是又暴露出了另一个问题。log.Fatal调用了os.Exit，会无条件终止程序；defer不会被调用到。**在生产环境中，不要轻易使用log.Fatal()，除非是在init()函数中或者在main函数一些解析或配置失败的情况下。**

## Application Lifecycle
对于应用的服务的管理，一般会抽象一个application lifecycle 的管理，方便服务的启动/停止等。go-kratos kit 库也按照类似的思路做了应用的生命周期托管。
- 应用的信息
- 服务的 start/stop
- 信号处理
- 服务注册
kit的使用者可以非常方便的对整个 application级别的资源进行托管，kratos中使用了errgroup + functional options 的方式进行了设计。

